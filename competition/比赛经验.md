## 数据处理

###

### 删除异常样本

除了简单除暴地删除，还可以用一种办法，那就是用树模型来训练，训练完后，每个样本会被分到叶子节点上，然后将(样本-均值)/方差，然后选取topN删掉。因为用一个叶子节点的数据应该比较相近，如果这个样本比较离群，那么我们可以认为这个样本可能是异常的，删掉可能会对效果有提升。

### 模型

1. xgboost lightgbm
2. rf gbdt gbdt+lr
3. fm ffm
4. 深度学习。在结构化数据中可能没有传统的机器学习方法效果好。

### 模型融合

1. 加权平均
2. 交集 并集
3. blending。比如说训练出了n个模型，然后在上面套个lr学习他们的权重。
4. stacking。这个存在过拟合风险，一般会将训练集切两份，第一个训练集训练出第一个模型，然后将结果作为特征和第二个训练集一起训练第二个模型。

### 线下验证集

一定要选择线下跟线上分布一样的验证集，不然线下线上区别会很大。

### 正负样本

可以通过采样，或者翻倍的办法解决不均衡问题

### 树模型如何处理类别特征

可以直接

### 如何挖掘新特征

用group

或者是根据一些重要性比较高的特征，来结合其他因素产生新的特征。比如他那次比赛的第一名就根据manage id生成了好多其他的特征，比如说好的manage经常出现在那个地理位置，在哪个时间点经常出现。这样结合一起能够产生一些比较好的特征。

挖掘特征之间的关联以及联合关系

一个好像是挺有用的东西

http://blog.datadive.net/interpreting-random-forests/

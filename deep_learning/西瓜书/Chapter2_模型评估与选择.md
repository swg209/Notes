## 2.2 评估方法

评估前，首先是划分数据集(train, val, test)

### 划分数据集

划分数据及的时候涉及到如何**sampling(采样)** ，这个问题有许多策略

- stratified sampling(分层采样)：保留类别比例的抽样方式，可避免train与test的数据分布差异导致的误差

划分的方式不同会导致训练结果不同。可以尝试若干次随机划分、重复实验然后取平均值作为结果。

另外，train与test**占总数据集的比例**也对结果有影响。比如：

- training data多，testing data少，testing data的分布可能就会与总分布不一致，导致test的结果不好
- training data少，testing data多，training data的分布可能就会与总分布不一致，model就会学得不好

### 验证法

**cross validation(交叉验证)**

K-flod cross validation(k折交叉验证)：将数据集D划分为k个等大小的互斥子集，每次取k-1个子集训练，剩下的1个做测试集；共训练k次，每个子集都当一回测试集。最后将k个结果去均值作为输出。**但是还没完！**，因为同一个数据集有多种划分子集的方式，所以需要用不同的划分方式做多次k-flod cv，比如常见有**10次10-flod cv**，然后将10次10-flod结果取均值，这才是最终输出。

- 优点：个人觉得挺好的
- 缺点：可能就在于比较繁琐，训练多次。不过次数自己定，挺灵活的。缺点不明显。

Leve-One-Out(留一法)：与k-flod一样，只不过这个方法的将一条数据作为一个子集

- 优点：比较准确，因为几乎把所有数据都作为了训练集
- 缺点：数据量大的时候开销非常大

****

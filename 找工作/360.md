360
华为面试回来之后，接到了360面试通知（提前批）。

部门： 核心安全事业部

岗位：机器学习/数据挖掘/自然语言处理工程师

一面：介绍了滴滴算法大赛，面试官比较关注特征工程。详细问了特征如何设计、为什么这么设计、那些特征会比较重要。商品推荐中如何进行个性化推荐，特征你会想到那些，为什么这么做

二面：避免过拟合策略、如何提高模型泛化能力、L1与L2正则区别，优缺点、生成式，判别式模型、深度学习这块了解多少、说说xgboost、gbdt区别、Tree-based Model如何处理连续型特征。

HR面：毕业之后比较注重什么、期望薪资、比较注重过程还是结果、对360的了解

能力测评：一个小时，题比较难，但是要好好做。认识的几个小伙伴都到了HR面，但是没有收到offer，不知道是不是能力测评的缘故。

---

360

1面： 背诵题 l1l2norm xgboost gbdt lr

2面：快排复杂度， 平均复杂度推导 + 背诵xgboost/gbdt + 聊天

---

面试官是个很温柔的小哥哥，全程把话语权交给你，全程40min

问：你能先自我介绍一下吗



问：你能给我说说你的项目吗

答：balabala



问：恩，思路比较清晰，那你能给我说一下xgboost吗？

答：xgboost的loss functionz加了L2正则以及限制叶子节点数，用到二阶求导，梯度下降更加准确，balabala。。。



问：你随遍挑个分类算法原理仔细推导

答：那我讲下支持向量机吧，此处省略一千字。。



问：时间序列模型你知道哪几个

答：猝不及防，ARIMA，讲了一堆arima



问：其实不止arima,你还知道啥吗？

答：本科学的，记不太清了



问：那你平时用python语言，都比较常用哪些包啊

答：numpy，scipy，pandas，tensorflow，sklearn。。。



问：你能给我说一下numpy，pandas吗

答：pandas我平时就用来数据清洗，读文件啊，连接啊，全然忘了两个重要的（Series，Dataframe），呜呜呜，后面面试官提醒了，numpy只能想到各种矩阵，呜呜呜。。



问：你在模型融合时，你会考虑哪些，为什么要融合，融合之后会提升很多吗？

答：主要考虑模型差异性吧，平时在选择时，我首选xgboos，不过各类模型都会试试，看看结果，再选定融合，感觉面试官不太相信融合



问：数据结构会吗，考你一下，问了不知道一个啥

答：我没系统学过数据结构，还在学，目前顶多了解一点排序



问：那我问你排序吧，（我真的是作死。。。），冒泡排序的平均时间复杂度

答：最好的情况是完全有序，是O（n），最坏的情况，此时仰望天空，发现大脑一片空白，于是开始现推，我说我想想，然后说O(n2)，因为他是两两比较



问：那空间复杂度呢？

答：不记得了。。。



问：考你一个冷门的排序方法，归并排序思想说说看

答：此时不知道多后悔说自己会排序。。。，之前看了现在忘了



问：没事，其实快排怎么怎么，不稳定，此时特别害怕又问我快排，幸好他发现我这块很弱，就说，算了不考你数据结构了，你这块还有欠缺，但你算法还是很扎实的

答：此时的我有点慌，我说我一直都是学统计，没有系统学过，他说可以理解，数据结构也只是辅助，答得不好没关系



问：你会hadoop吗？

答：会一点点，有了上次教训，不敢声称自己会



问：那你给我说说mapreduce

答：我说这是分布式处理，举了个例子，讲的很浅显



问：其实mapreduce大概就这个思想吧，你说的过于简单了，实际上处理还是很复杂的

答：是的，我还只懂些皮毛



问：那你会spark吗

答：直接答只懂一点点，还在看，害怕，其实稍微知道点RDD



问:那你给我说说。。。

答：（他问的我至今不知道是啥，应该是某种方法，四个字母）我说不会



问：没事，反正现在国内能解释清楚这个的也没几个人，然后一个人笑

答：此时的我。。。。



问：你会c吗

答：不会，我平时主要用python，R



他总结：你才研一啊，算法那边是一点问题也没有，很不错，数据结构可能你不是科班的，不懂也很正常，其实我们公司主要是与阿里云合作。。。。运用机器学习

干嘛干嘛，数据平时也是时间序列数据，介绍了一下部门情况，然后问，你有什么要问我的吗？

我说：面试结果什么时候出来啊，

他说：大概一周吧，后续有进度会继续通知你的

然后，我说我感觉我还是会的太少，还要多补补，然后谢谢他，再见



面完感觉：真的很累，感觉整个人被掏空，本来还想show一下推荐系统的，想了一下，感觉面试官啥都很熟，我怕是不要给自己挖坑了，就这样吧

面试给我的感觉，还不错，毕竟全程一直在肯定我的算法功底，但是感觉很迷，希望后续再加油！

---

最大公约数最小公倍数 链表倒数第k个数，程序思路 快排思路 B-树，B 树区别和原理，效率，应用场景 红黑树

排序算法有哪些，复杂度
复杂度相同，快排的优势

栈和队列的区别

---

作者：BATcome
链接：https://www.nowcoder.com/discuss/50923?type=2&order=0&pos=29&page=1
来源：牛客网

alexnet的网络结构，自己试验是怎么基于AlexNet改进的；（貌似是5个卷积层，2个全连接层加一个softmax吧）
batch normolization原理是什么，实验的收敛速度增大了多少；（提升了3倍，我的）
VGG网络相比于AlexNet改进的地方在哪里，为什么（把77卷积核换成了33，因为1是卷积参数个数变少了，2是增加了非线性变换）
然后楼主强行安利了一发Relu和Sigmoid函数之间的差别（1.不会梯度弥散；2.稀疏参数；3.计算简单）
后来又问了一下LR和SVM的差别（同为2分类，SVM用的是hinge loss，LR用的是逻辑回归）
最后考了一道现场编程题，vector nums{2,3,4,5},target = 7，返回组成7的全部组合{{2,2,3},{2,5},{3,4}}这样子(一道深度优先算法，leetcode上就有，在此就不再赘述了)
至此就面过了一面，出来刷公众号就发现自己过了，等了20分钟就开始二面：
二面面试官主要就是问实习的经历了：
1.实习期间hash编码是怎么做的（cnn提取特征哈哈）
2.第二段的实习是做了什么（写了C++的提取feature_map的工具，并且做了网络压缩的工作）
3.简单说一下caffe你要重写类的话，要怎么加么（虽然一脸懵逼，但答了loss层加上layersetup,forward,backward,data层继承基础类）
4.由3引申出来问了caffe的类的工厂模式懂么？为什么caffe写了类放在相应目录下就可以？类的注册？（我说caffe类有一个factory.cpp中吧，里面定义了）
5.由4引申出来的手撕代码...写一个简单的工厂模式...C++代码（= =还好真看过不然就挂了）
然后二面就过了哈哈，出来等了1个小时进入了hr面，差不多就算进入了吹水环节吧：
1.机器学习和深度学习的区别是什么？（数学完成，经验驱动；数据量少，数据量大；）
2.你的缺点是什么。。（典型面试问题。。哈哈）
3.你有遇到需要计划的事儿么（这必须有啊。。将自己的经历）
3.如果给你百度的offer。。你会选哪个？（。。。。）
4.有什么想问的（我就问了现在AI研究院的状态）

---

作者：happyYolanda
链接：https://www.nowcoder.com/discuss/91?type=2&order=0&pos=14&page=2
来源：牛客网

今天面试360搜索通过了，谢谢牛客网的内推，在这里把面试中问到的问题总结出来。我是个菜鸟，希望能给别人一些帮助。

下面是正题：
360的面试官感觉很nice，不会让人觉得很紧张。进来后先问了我项目，包括之前做的一个安卓游戏，微博搜索引擎，一个数据挖掘项目和编译器。问到的问题包括，让我写出抽象语法树，聚类算法（项目中使用到的），算法的比较和改进。重点问了搜索引擎。我把之前做过的搜索引擎的实现框架说完后，他就问了倒排索引如何实现，如何处理同义词，如何在不把倒排索引放入内存的情况下实现两个词项搜索的并集，并且让我写出了搜索引擎的实现框架（对自己熟悉的地方详细些，不熟悉的地方可以写出大概来），最后问了我分词的原理。算法题考的是给出两个有序数组，找出第k个大的元素。

我就只有一面，本来正在屋里准备二面，然后HR姐姐过来跟我说不用二面了。我以为就这样挂了，过了一会给我打电话说通过了。
这是我的第一个offer，再次感谢牛客网，还有传说中的叶神，然后就继续努力吧！

---

作者：crazyhoney
链接：https://www.nowcoder.com/discuss/32008?type=2&order=0&pos=18&page=4
来源：牛客网

2017-09-04-360-大数据算法-1面-内推-视频
1、自我介绍

2、说项目

3、说一下项目中用的Kmeans算法

4、知道哪几种聚类算法，说下原理

5、Kmeans有什么优缺点

6、项目用了RNN，说一下RNN原理

说了RNN原理，顺便说了LSTM/GRU的出现

7、为什么会出现长时依赖的问题

8、LSTM/GRU如何解决长时依赖的问题

9、写代码：

一个有序数组中查找某个数

一开始写了个遍历查找，面试官说，还能再快吗？

然后写了个二分查找

---

给200个200个数的数组，找到最大的200个

未排序的数组中查找中间的那个数，O(NlogN) , O(N) ?

如何通过3L和5L的桶构造N升的水，写程序

实现一个有N个工件，M种类，找出最小的子序列包含M个工件。我实现了一个时间O（N），空间O（M）的方法。以前做过原题

---

作者：zha硕没offer
链接：https://www.nowcoder.com/discuss/59595?type=2&order=0&pos=21&page=1
来源：牛客网

360：
360是最早的一批，刚开始还很高兴的以为过了，但是给我扔到了备胎池，现在都没消息。
一面：
1.先自我介绍一下
2.介绍了比赛和项目经验
3.讲下xgboost的原理
4.两道编程题：
先是让写字符串的距离，看我不会换成了链表的反转
5.面试官介绍了下部门的主要业务
6.问我还有什么想问的
时长1小时

二面：
1.自我介绍
2.介绍下项目
3.stacking怎么做的
4.有没有自己实现过算法
5.gbdt输出特征到lr再训练有没有做过
6.你可以走了
全程20分钟

三面（HR面）：
1.实验室主要做什么
2.比赛是几个人做的，怎么分工的
3.有没有实习过
4.除了做比赛还有什么准备
研一的时候就一直在准备，选了很多相关的课程，模式识别，机器学习，数据挖掘
5.为什么做比赛
提升工程能力以及运用机器学习方法解决实际问题的能力
6.能不能来实习
7.分别说出自己的三个优点和缺点

---

作者：我不是渣神
链接：https://www.nowcoder.com/discuss/36815?type=2&order=0&pos=44&page=4
来源：牛客网

三、360提前批
第一次现场面，完全不知道面试是什么套路，稀烂。
1、介绍xgboost一下。写下xgboost目标函数。（因为我提到xgboost在目标函数里显式地加入了正则项..血雪崩）
2、问项目里英语分词器用了啥，jieba用过吗，怎么调整XGB参数，除了logloss用了别的评估方式吗
3、了解其他的分类模型吗，问LR缺点，LR怎么推导（当时我真没准备好，写不出来）
4、写LR目标函数，目标函数怎么求最优解（也不会）
5、讲讲LR的梯度下降，梯度下降有哪几种
6、写代码：快拍，如何写非递归的快排（不会非递归）
7、写代码：最长公共子序列（当时不会写，DP，左神书P210）
7、逻辑函数是啥（Log-Sigmoid，1/(1+e^(-x))）
8、机器学习的模型自己实现过吗（对不起我是真开局一卷草席，装备全靠捡）
8、word2vec是怎么实现的
9、nlp做过吗？讲一讲textrank如何做的（有用过）
10、写一下信息增益
女面试官语重心长地对我说，你小子一个应届生，基础差得一批，啥啥不会，我们这要实现算法的，赶紧滚回去巩固基础，并且多自己实现实现。
